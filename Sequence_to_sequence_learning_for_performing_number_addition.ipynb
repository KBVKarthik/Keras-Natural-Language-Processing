{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence to sequence learning for performing number addition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvkrpvwJ7/jGYmie+44lpv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KBVKarthik/Keras-Natural-Language-Processing/blob/main/Sequence_to_sequence_learning_for_performing_number_addition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ZebA-9F2ML"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "\n",
        "\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvV7OWufF-lo",
        "outputId": "70ed425d-5559-4e31-b1b0-7fd1655b7ee5"
      },
      "source": [
        "class CharacterTable:\n",
        "\n",
        "\n",
        "    def __init__(self, chars):\n",
        "\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return \"\".join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "  \n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print(\"Total questions:\", len(questions))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqB2uXd-GHGW",
        "outputId": "656f7e0d-9a6d-47f0-ea6b-f649e031a6fe"
      },
      "source": [
        "print(\"Vectorization...\")\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n",
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u2wqetIGML6",
        "outputId": "05852f51-a282-4ef5-c9e9-8c6a7e08784e"
      },
      "source": [
        "print(\"Build model...\")\n",
        "num_layers = 1  \n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
        "\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "\n",
        "for _ in range(num_layers):\n",
        "\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KdNvTQ1GSoR",
        "outputId": "d840a72c-b018-4820-8a90-d7ff755b5b1e"
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 22s 10ms/step - loss: 1.7588 - accuracy: 0.3568 - val_loss: 1.5567 - val_accuracy: 0.4216\n",
            "Q 9+414   T 423  ☒ 144 \n",
            "Q 35+14   T 49   ☒ 12  \n",
            "Q 700+765 T 1465 ☒ 1366\n",
            "Q 973+2   T 975  ☒ 900 \n",
            "Q 99+412  T 511  ☒ 100 \n",
            "Q 95+251  T 346  ☒ 510 \n",
            "Q 513+971 T 1484 ☒ 1566\n",
            "Q 787+521 T 1308 ☒ 1360\n",
            "Q 455+2   T 457  ☒ 550 \n",
            "Q 381+12  T 393  ☒ 390 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3308 - accuracy: 0.5031 - val_loss: 1.1534 - val_accuracy: 0.5761\n",
            "Q 0+784   T 784  ☒ 788 \n",
            "Q 18+54   T 72   ☒ 88  \n",
            "Q 401+30  T 431  ☒ 435 \n",
            "Q 626+12  T 638  ☒ 636 \n",
            "Q 723+981 T 1704 ☒ 1798\n",
            "Q 870+439 T 1309 ☒ 1396\n",
            "Q 9+152   T 161  ☒ 159 \n",
            "Q 128+917 T 1045 ☒ 1018\n",
            "Q 552+29  T 581  ☒ 587 \n",
            "Q 873+3   T 876  ☒ 878 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0353 - accuracy: 0.6149 - val_loss: 0.9333 - val_accuracy: 0.6551\n",
            "Q 7+913   T 920  ☒ 929 \n",
            "Q 28+45   T 73   ☒ 79  \n",
            "Q 42+929  T 971  ☒ 970 \n",
            "Q 29+3    T 32   ☒ 39  \n",
            "Q 461+9   T 470  ☒ 469 \n",
            "Q 14+617  T 631  ☒ 638 \n",
            "Q 143+13  T 156  ☒ 151 \n",
            "Q 8+204   T 212  ☒ 214 \n",
            "Q 477+225 T 702  ☒ 701 \n",
            "Q 190+9   T 199  ☒ 190 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8648 - accuracy: 0.6820 - val_loss: 0.7971 - val_accuracy: 0.7106\n",
            "Q 417+744 T 1161 ☒ 1150\n",
            "Q 12+84   T 96   ☒ 95  \n",
            "Q 38+88   T 126  ☒ 123 \n",
            "Q 120+21  T 141  ☒ 148 \n",
            "Q 146+6   T 152  ☒ 151 \n",
            "Q 40+532  T 572  ☒ 578 \n",
            "Q 486+55  T 541  ☒ 542 \n",
            "Q 76+12   T 88   ☒ 85  \n",
            "Q 11+891  T 902  ☑ 902 \n",
            "Q 44+801  T 845  ☒ 848 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.7522 - accuracy: 0.7243 - val_loss: 0.7070 - val_accuracy: 0.7422\n",
            "Q 733+119 T 852  ☒ 859 \n",
            "Q 504+628 T 1132 ☒ 1138\n",
            "Q 92+149  T 241  ☒ 242 \n",
            "Q 2+735   T 737  ☑ 737 \n",
            "Q 659+619 T 1278 ☑ 1278\n",
            "Q 478+493 T 971  ☒ 967 \n",
            "Q 741+759 T 1500 ☒ 1409\n",
            "Q 702+22  T 724  ☒ 725 \n",
            "Q 811+185 T 996  ☒ 999 \n",
            "Q 410+457 T 867  ☒ 869 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.6398 - accuracy: 0.7672 - val_loss: 0.5401 - val_accuracy: 0.8019\n",
            "Q 6+876   T 882  ☒ 881 \n",
            "Q 979+10  T 989  ☒ 988 \n",
            "Q 14+991  T 1005 ☒ 1007\n",
            "Q 42+929  T 971  ☑ 971 \n",
            "Q 570+23  T 593  ☒ 592 \n",
            "Q 208+318 T 526  ☒ 534 \n",
            "Q 163+530 T 693  ☒ 692 \n",
            "Q 42+73   T 115  ☒ 116 \n",
            "Q 580+527 T 1107 ☒ 1100\n",
            "Q 23+296  T 319  ☒ 310 \n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.3869 - accuracy: 0.8712 - val_loss: 0.2825 - val_accuracy: 0.9159\n",
            "Q 843+850 T 1693 ☑ 1693\n",
            "Q 271+4   T 275  ☑ 275 \n",
            "Q 209+330 T 539  ☒ 549 \n",
            "Q 491+85  T 576  ☒ 577 \n",
            "Q 38+427  T 465  ☑ 465 \n",
            "Q 996+29  T 1025 ☑ 1025\n",
            "Q 80+50   T 130  ☒ 131 \n",
            "Q 600+30  T 630  ☒ 631 \n",
            "Q 935+54  T 989  ☑ 989 \n",
            "Q 568+69  T 637  ☒ 636 \n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.2244 - accuracy: 0.9386 - val_loss: 0.1854 - val_accuracy: 0.9516\n",
            "Q 997+332 T 1329 ☑ 1329\n",
            "Q 58+282  T 340  ☑ 340 \n",
            "Q 2+802   T 804  ☑ 804 \n",
            "Q 48+5    T 53   ☒ 54  \n",
            "Q 79+73   T 152  ☑ 152 \n",
            "Q 362+70  T 432  ☑ 432 \n",
            "Q 439+119 T 558  ☒ 567 \n",
            "Q 382+408 T 790  ☒ 799 \n",
            "Q 526+320 T 846  ☑ 846 \n",
            "Q 0+363   T 363  ☑ 363 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.1479 - accuracy: 0.9632 - val_loss: 0.1152 - val_accuracy: 0.9739\n",
            "Q 823+212 T 1035 ☑ 1035\n",
            "Q 690+30  T 720  ☑ 720 \n",
            "Q 5+697   T 702  ☑ 702 \n",
            "Q 8+182   T 190  ☑ 190 \n",
            "Q 491+421 T 912  ☑ 912 \n",
            "Q 716+20  T 736  ☑ 736 \n",
            "Q 768+73  T 841  ☑ 841 \n",
            "Q 52+910  T 962  ☑ 962 \n",
            "Q 46+312  T 358  ☑ 358 \n",
            "Q 351+94  T 445  ☑ 445 \n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.1050 - accuracy: 0.9747 - val_loss: 0.1296 - val_accuracy: 0.9591\n",
            "Q 991+3   T 994  ☑ 994 \n",
            "Q 39+57   T 96   ☑ 96  \n",
            "Q 148+727 T 875  ☑ 875 \n",
            "Q 614+437 T 1051 ☑ 1051\n",
            "Q 17+881  T 898  ☑ 898 \n",
            "Q 799+12  T 811  ☑ 811 \n",
            "Q 135+432 T 567  ☑ 567 \n",
            "Q 567+273 T 840  ☑ 840 \n",
            "Q 255+7   T 262  ☑ 262 \n",
            "Q 93+320  T 413  ☑ 413 \n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.0837 - accuracy: 0.9797 - val_loss: 0.0633 - val_accuracy: 0.9855\n",
            "Q 29+99   T 128  ☑ 128 \n",
            "Q 390+53  T 443  ☑ 443 \n",
            "Q 31+971  T 1002 ☑ 1002\n",
            "Q 20+33   T 53   ☑ 53  \n",
            "Q 34+212  T 246  ☑ 246 \n",
            "Q 64+745  T 809  ☑ 809 \n",
            "Q 742+443 T 1185 ☑ 1185\n",
            "Q 78+34   T 112  ☑ 112 \n",
            "Q 338+840 T 1178 ☑ 1178\n",
            "Q 159+6   T 165  ☑ 165 \n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.0870 - val_accuracy: 0.9734\n",
            "Q 79+678  T 757  ☒ 756 \n",
            "Q 334+36  T 370  ☑ 370 \n",
            "Q 274+966 T 1240 ☑ 1240\n",
            "Q 526+63  T 589  ☑ 589 \n",
            "Q 30+115  T 145  ☑ 145 \n",
            "Q 651+725 T 1376 ☑ 1376\n",
            "Q 63+519  T 582  ☑ 582 \n",
            "Q 107+475 T 582  ☑ 582 \n",
            "Q 14+606  T 620  ☑ 620 \n",
            "Q 8+960   T 968  ☑ 968 \n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0526 - accuracy: 0.9874 - val_loss: 0.0474 - val_accuracy: 0.9876\n",
            "Q 207+626 T 833  ☑ 833 \n",
            "Q 95+36   T 131  ☑ 131 \n",
            "Q 14+82   T 96   ☑ 96  \n",
            "Q 551+529 T 1080 ☑ 1080\n",
            "Q 80+432  T 512  ☑ 512 \n",
            "Q 86+79   T 165  ☑ 165 \n",
            "Q 593+9   T 602  ☑ 602 \n",
            "Q 13+863  T 876  ☑ 876 \n",
            "Q 662+516 T 1178 ☑ 1178\n",
            "Q 114+535 T 649  ☑ 649 \n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9881 - val_loss: 0.0304 - val_accuracy: 0.9935\n",
            "Q 249+48  T 297  ☑ 297 \n",
            "Q 7+276   T 283  ☑ 283 \n",
            "Q 29+738  T 767  ☑ 767 \n",
            "Q 749+70  T 819  ☑ 819 \n",
            "Q 143+852 T 995  ☑ 995 \n",
            "Q 51+226  T 277  ☑ 277 \n",
            "Q 940+742 T 1682 ☑ 1682\n",
            "Q 51+13   T 64   ☑ 64  \n",
            "Q 9+358   T 367  ☑ 367 \n",
            "Q 70+24   T 94   ☑ 94  \n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.0461 - accuracy: 0.9883 - val_loss: 0.0327 - val_accuracy: 0.9918\n",
            "Q 936+734 T 1670 ☑ 1670\n",
            "Q 891+292 T 1183 ☑ 1183\n",
            "Q 797+171 T 968  ☑ 968 \n",
            "Q 914+881 T 1795 ☑ 1795\n",
            "Q 543+3   T 546  ☑ 546 \n",
            "Q 849+498 T 1347 ☑ 1347\n",
            "Q 564+49  T 613  ☑ 613 \n",
            "Q 3+822   T 825  ☑ 825 \n",
            "Q 635+431 T 1066 ☑ 1066\n",
            "Q 577+14  T 591  ☑ 591 \n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0321 - val_accuracy: 0.9911\n",
            "Q 17+686  T 703  ☑ 703 \n",
            "Q 131+851 T 982  ☑ 982 \n",
            "Q 30+618  T 648  ☑ 648 \n",
            "Q 255+86  T 341  ☑ 341 \n",
            "Q 69+593  T 662  ☑ 662 \n",
            "Q 398+40  T 438  ☒ 428 \n",
            "Q 201+591 T 792  ☑ 792 \n",
            "Q 41+93   T 134  ☑ 134 \n",
            "Q 960+915 T 1875 ☑ 1875\n",
            "Q 309+535 T 844  ☑ 844 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 13s 10ms/step - loss: 0.0377 - accuracy: 0.9899 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
            "Q 221+657 T 878  ☑ 878 \n",
            "Q 583+512 T 1095 ☑ 1095\n",
            "Q 930+898 T 1828 ☑ 1828\n",
            "Q 49+813  T 862  ☑ 862 \n",
            "Q 0+492   T 492  ☑ 492 \n",
            "Q 938+74  T 1012 ☑ 1012\n",
            "Q 30+70   T 100  ☑ 100 \n",
            "Q 693+913 T 1606 ☑ 1606\n",
            "Q 3+638   T 641  ☑ 641 \n",
            "Q 925+950 T 1875 ☑ 1875\n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0288 - accuracy: 0.9924 - val_loss: 0.0214 - val_accuracy: 0.9950\n",
            "Q 806+717 T 1523 ☑ 1523\n",
            "Q 623+41  T 664  ☑ 664 \n",
            "Q 397+191 T 588  ☑ 588 \n",
            "Q 720+63  T 783  ☑ 783 \n",
            "Q 425+1   T 426  ☑ 426 \n",
            "Q 463+702 T 1165 ☑ 1165\n",
            "Q 513+455 T 968  ☑ 968 \n",
            "Q 99+361  T 460  ☑ 460 \n",
            "Q 90+542  T 632  ☑ 632 \n",
            "Q 143+94  T 237  ☑ 237 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 0.0199 - val_accuracy: 0.9948\n",
            "Q 16+428  T 444  ☑ 444 \n",
            "Q 235+231 T 466  ☑ 466 \n",
            "Q 17+304  T 321  ☑ 321 \n",
            "Q 110+84  T 194  ☑ 194 \n",
            "Q 33+318  T 351  ☑ 351 \n",
            "Q 765+42  T 807  ☑ 807 \n",
            "Q 120+21  T 141  ☑ 141 \n",
            "Q 335+47  T 382  ☑ 382 \n",
            "Q 642+485 T 1127 ☑ 1127\n",
            "Q 64+132  T 196  ☑ 196 \n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0260 - accuracy: 0.9930 - val_loss: 0.0336 - val_accuracy: 0.9891\n",
            "Q 20+33   T 53   ☑ 53  \n",
            "Q 710+16  T 726  ☑ 726 \n",
            "Q 651+662 T 1313 ☑ 1313\n",
            "Q 8+560   T 568  ☑ 568 \n",
            "Q 402+381 T 783  ☑ 783 \n",
            "Q 695+6   T 701  ☑ 701 \n",
            "Q 416+82  T 498  ☑ 498 \n",
            "Q 193+192 T 385  ☑ 385 \n",
            "Q 440+89  T 529  ☑ 529 \n",
            "Q 201+25  T 226  ☑ 226 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0233 - val_accuracy: 0.9932\n",
            "Q 515+278 T 793  ☑ 793 \n",
            "Q 7+292   T 299  ☑ 299 \n",
            "Q 2+802   T 804  ☑ 804 \n",
            "Q 28+74   T 102  ☑ 102 \n",
            "Q 363+52  T 415  ☑ 415 \n",
            "Q 594+429 T 1023 ☑ 1023\n",
            "Q 44+801  T 845  ☑ 845 \n",
            "Q 38+834  T 872  ☑ 872 \n",
            "Q 43+346  T 389  ☑ 389 \n",
            "Q 931+55  T 986  ☑ 986 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.0099 - val_accuracy: 0.9981\n",
            "Q 50+463  T 513  ☑ 513 \n",
            "Q 45+930  T 975  ☑ 975 \n",
            "Q 75+52   T 127  ☑ 127 \n",
            "Q 60+759  T 819  ☑ 819 \n",
            "Q 557+551 T 1108 ☑ 1108\n",
            "Q 103+860 T 963  ☑ 963 \n",
            "Q 46+264  T 310  ☑ 310 \n",
            "Q 185+433 T 618  ☑ 618 \n",
            "Q 30+704  T 734  ☑ 734 \n",
            "Q 52+813  T 865  ☑ 865 \n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0324 - val_accuracy: 0.9908\n",
            "Q 382+23  T 405  ☑ 405 \n",
            "Q 378+309 T 687  ☑ 687 \n",
            "Q 15+549  T 564  ☑ 564 \n",
            "Q 32+69   T 101  ☑ 101 \n",
            "Q 1+998   T 999  ☑ 999 \n",
            "Q 99+412  T 511  ☑ 511 \n",
            "Q 84+378  T 462  ☑ 462 \n",
            "Q 675+59  T 734  ☑ 734 \n",
            "Q 425+30  T 455  ☑ 455 \n",
            "Q 4+320   T 324  ☑ 324 \n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Q 54+449  T 503  ☑ 503 \n",
            "Q 323+73  T 396  ☑ 396 \n",
            "Q 26+619  T 645  ☑ 645 \n",
            "Q 699+62  T 761  ☑ 761 \n",
            "Q 238+517 T 755  ☑ 755 \n",
            "Q 334+36  T 370  ☑ 370 \n",
            "Q 382+408 T 790  ☑ 790 \n",
            "Q 97+279  T 376  ☑ 376 \n",
            "Q 73+712  T 785  ☑ 785 \n",
            "Q 311+35  T 346  ☑ 346 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.0081 - val_accuracy: 0.9989\n",
            "Q 102+164 T 266  ☑ 266 \n",
            "Q 13+376  T 389  ☑ 389 \n",
            "Q 38+80   T 118  ☑ 118 \n",
            "Q 36+930  T 966  ☑ 966 \n",
            "Q 45+320  T 365  ☑ 365 \n",
            "Q 260+9   T 269  ☑ 269 \n",
            "Q 17+951  T 968  ☑ 968 \n",
            "Q 51+172  T 223  ☑ 223 \n",
            "Q 17+233  T 250  ☑ 250 \n",
            "Q 913+22  T 935  ☑ 935 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.1152 - val_accuracy: 0.9611\n",
            "Q 30+639  T 669  ☑ 669 \n",
            "Q 414+34  T 448  ☑ 448 \n",
            "Q 997+870 T 1867 ☑ 1867\n",
            "Q 180+76  T 256  ☑ 256 \n",
            "Q 8+743   T 751  ☑ 751 \n",
            "Q 781+202 T 983  ☑ 983 \n",
            "Q 178+892 T 1070 ☑ 1070\n",
            "Q 91+983  T 1074 ☒ 1065\n",
            "Q 3+440   T 443  ☑ 443 \n",
            "Q 299+114 T 413  ☒ 513 \n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.0118 - val_accuracy: 0.9970\n",
            "Q 44+77   T 121  ☑ 121 \n",
            "Q 234+6   T 240  ☑ 240 \n",
            "Q 823+890 T 1713 ☑ 1713\n",
            "Q 204+72  T 276  ☑ 276 \n",
            "Q 5+187   T 192  ☑ 192 \n",
            "Q 801+339 T 1140 ☑ 1140\n",
            "Q 928+60  T 988  ☑ 988 \n",
            "Q 28+92   T 120  ☑ 120 \n",
            "Q 681+9   T 690  ☑ 690 \n",
            "Q 69+324  T 393  ☑ 393 \n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0251 - accuracy: 0.9934 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Q 4+183   T 187  ☑ 187 \n",
            "Q 524+92  T 616  ☑ 616 \n",
            "Q 0+907   T 907  ☑ 907 \n",
            "Q 96+7    T 103  ☑ 103 \n",
            "Q 73+554  T 627  ☑ 627 \n",
            "Q 2+202   T 204  ☑ 204 \n",
            "Q 27+931  T 958  ☑ 958 \n",
            "Q 569+59  T 628  ☑ 628 \n",
            "Q 21+700  T 721  ☑ 721 \n",
            "Q 84+33   T 117  ☑ 117 \n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 0.0062 - val_accuracy: 0.9991\n",
            "Q 93+209  T 302  ☑ 302 \n",
            "Q 936+71  T 1007 ☑ 1007\n",
            "Q 41+413  T 454  ☑ 454 \n",
            "Q 65+300  T 365  ☑ 365 \n",
            "Q 862+55  T 917  ☑ 917 \n",
            "Q 296+78  T 374  ☑ 374 \n",
            "Q 316+809 T 1125 ☑ 1125\n",
            "Q 10+659  T 669  ☑ 669 \n",
            "Q 980+85  T 1065 ☑ 1065\n",
            "Q 50+78   T 128  ☑ 128 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}